

五、Redis持久化（RDB,AOF）（Redis DataBase）☆☆☆重点☆☆☆
RDB（dump.rdb）：在指定的时间内将内存中的数据集快照写入磁盘内，
也就是行话讲的snapshot（快照）
它恢复时是将快照文件直接读入内存
		
Redis会单独创建（fork）一个子进程来进行持久化，它会将现有数据写入
到一个临时文件中
等持久化过程结束了，将这个临时文件替换上次的持久化文件，
整个过程主进程不进行任何IO操作，确保了极高性能
对于数据恢复的完整性不是非常敏感，RDB比AOF更加高效，缺点在于最后一次持久化可能丢失

Fork的作用就是复制一个与当前进程一样的，
新进程中所有数据包含变量，环境变量，程序计数器等
都与原来的进程一致，但是是一个全新的，作为原来的子进程

相关配置：（如果想禁用RDB持久化的策略，只要不设置任何save指令，或者给save传入一个空字符串参数也可以）
save/bgsave/lastsave
stop-writes-on-bgsave-error（如果配置成no，表示你不在乎数据不一致或者有其他的手段发现和控制）
rdbcompression（对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用
LZF算法进行压缩。如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能）
rdbchecksum：在存储快照后，还可以让redis使用CRC64算法来进行数据校验，
但是这样做会增加大约
10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能
dbfilename
dir




如何触发：
	1.冷拷贝后重新使用
	2.save还是bgsave：（save只管保存，其它不管，全部阻塞）
			  （bgsave会在后台进行快照操作，同时还可以响应客户请求
			    可以使用lastsave获取最后一次快照时间）
	3.flushall（无意义）或者shutdown默认都会进行保存

恢复：将备份文件移动到redis安装目录启动服务就可以
      使用config get dir可以获取目录

优势：适合大规模数据恢复，对数据的完整与一致性要求不高
劣势：一段时间一次备份，中间redis如果down掉，
      就会丢失最后一次的修改
      内存数据被克隆一份，大致2倍的膨胀性需要考虑

动态停止：config set save ""
           config get appendonly





AOF:(appendonly.aof):Append Of File
以日志的形式记录每个写操作，将redis执行的所有写操作记录，读不管
只追加但不可改写，redis启动会读取该文件再重新执行一遍来完成恢复

原始的命令		  重写后的(节约空间)

set k1 1		===>set k1 20
incrby k1 6		    
incrby k1 3
incrby k1 4  
incr k1
incr k1
incr k1
incr k1
incr k1
incr k1
decr k1
incr k1



相关配置：
appendonly(redis默认使用的是rdb，aof是关闭的)
appendfilename(默认是appendonly.aof)
appendfsync（3种策略记录日志。默认都是采用每秒记录一次）
no-appendfsync-on-rewrite：重写时是否可以运用appendfysnc，用默认no可保证安全性
auto-aof-rewrite-min-size：重写基准值
auto-aof-rewrite-percentage：重写基准值


fsync

启动：设置yes，将文件保存在安装目录，启动
RESP协议 是redis客户端和服务端之间使用的一种通讯协议
异常（备份写坏的aof文件）使用命令redis-check-aof --fix 文件修复
(注意：在linux系统中还有一个命令redis-check-rdb用来修复rdb文件
但在window版本中没有)

重写(rewrite)原理：aof文件持续增长过大时，会fork一条新进程将文件重写
遍历新进程的内存数据，每有一条set，就重写aof操作，不读取旧的aof文件
而是将整个内存的数据库内容用命令再写一遍新的aof

触发机制：
与上面的重写基准值相关（一倍大小且文件大于多少（一般3-5G））


优势：同步更精确，如果一秒内宕机会有数据丢失
劣势：aof运行效率比rdb慢，恢复速度慢，备份要注意
(备份时很有可能同时在往该日志文件中写入命令,一般公司aof的
备份时间都会选择在凌晨，由运维人员负责)


用哪个：官方推荐rdb，只做缓存都不用，aof优先rdb，建议不要只用一种


因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，
而且只要15分钟备份一次就够了，只保留save 900 1这条规则。
如果Enalbe AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，
启动脚本较简单只load自己的AOF文件就可以了。
代价一是带来了持续的IO，
二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。
只要硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，
可以设到5G以上。默认超过原大小100%大小时重写可以改到适当的数值。
如果不Enable AOF ，仅靠Master-Slave Replication 实现高可用性也可以。
能省掉一大笔IO也减少了rewrite时带来的系统波动。
代价是如果Master/Slave同时倒掉，会丢失十几分钟的数据，
启动脚本也要比较两个Master/Slave中的RDB文件，载入较新的那个。
新浪微博就选用了这种架构





==========================================================
redis本来存储的就是高频热点数据

----》id为63797979---》查数据库（没有）找理论操作不会有对象存入缓存
但是我就将id为63797979的值作为key，value就是一个“”存入缓存中
那么下次用户如果还访问的是63797979，我们缓存中就有了该对象

1.缓存穿透：客户循环100万次恶意查询id为空或者不存在的对象，缓存中无法找到
	   对象，所以所有的请求都会穿过缓存直接访问DB，造成DB宕机
解决方案：在缓存中自己存入空对象，使客户的访问在缓存中能找到
	   这个缓存的空对象与数据库没有任何关系，就是为了解决穿透的问题


2.缓存击穿：客户在访问某个热点高频数据的时候，刚好缓存中的
	    key失效（时间到了或者被缓存满了被清理了）
            那么这次的请求缓存中无法找到，会直接打到DB上。
	    这就是我们的击穿.
解决方案： 使用BloomFilter(布隆过滤器,设置某些热点key永不过期)


3.缓存雪崩：就是和上面的缓存击穿类似，但是不同的地方在于
            在同一时间点有大量的key同时过期，某个时间点
	    所有的请求在缓存中都无法找到，全部打到DB上
	    这就是我们的缓存雪崩
解决方案：设置key的过期时间不同，一般在原来的时间设置基础上
           可以加上某个小的随机数，就是为了让这些key不要在同一时间
	   一起过期造成雪崩，而将压力时间点分摊开

关于上面提到的缓存问题，大家可以自己百度了解，也可以
自己了解下什么是BloomFilter，另外可以学习JMS，然后进阶
了解下消息中间件技术，例如：RabbitMQ和ActiveMQ和KafKa





=====================================================================

六、Redis事务
按照顺序串行化执行，而不会被插入，
如果中间出现问题（大家理解为编译期语法错误等，则全部失败）
如果中间出现问题（大家理解为运行期空指针等，则部分失败）
非强一致性
MULTI（开始）
EXEC（执行）
DISCARD（放弃）
WATCH key。。（监控一个或者多个key）（乐观锁，悲观锁，CAS（Check-And-Set））
先监控，再开事务，如果监控后有对监控key的修改，后面的事务失效
执行了EXEC后，前面的锁都会被自动放掉
UNWATCH（取消对key的监控）



七、Redis发布订阅（消息中间件【了解】）
就是一种进程间的通讯方式，大家可以有点将它理解为udp，先
订阅SUBSCRIBE某个频道，再向某个频道发布PUBLISH消息
SUBSCRIBE c（订阅一个或者多个频道）
PSUBSCRIBE c*（订阅一个或者多个频道,允许通配符）
PUBLISH c m（发布消息）
UNSUBSCRIBE c
PUNSUBSCRIBE（退订，允许通配符）


八、Redis复制（master/slave）
九、Jedis